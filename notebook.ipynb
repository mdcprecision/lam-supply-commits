{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b9266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from openpyxl import load_workbook\n",
    "import pyodbc\n",
    "from datetime import datetime, timedelta\n",
    "import numpy\n",
    "\n",
    "FILENAME = 'MDC Q1 Playbook Lam WEEKLY UPDATES.xlsx'\n",
    "OUTPUT_FILENAME = 'MDC Q1 Playbook Lam WEEKLY UPDATES - updated.xlsx'\n",
    "SHEET_NAME = 'MDC Supply Commits'\n",
    "UPDATED_SHEET_NAME = SHEET_NAME + ' - updated'\n",
    "FAIR_SHEET_NAME = 'MDC Q1 Playbook'\n",
    "\n",
    "CONNECTION_STRING = f'\\\n",
    "            DRIVER={{ODBC Driver 17 for SQL Server}};\\\n",
    "            ENCRYPT=no;\\\n",
    "            SERVER=172.20.103.105;\\\n",
    "            DATABASE=MDC_AX2009SP1_PROD;\\\n",
    "            UID=USSQLUser;\\\n",
    "            PWD=Insp1r0n2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39f462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pkastner\\Documents\\lam-supply-commits\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "commits_orig = pd.read_excel(FILENAME, sheet_name=SHEET_NAME)\n",
    "commits_orig.insert(1, 'Type', '')\n",
    "\n",
    "# clear out existing values\n",
    "commits_orig.iloc[:, 5:-1] = numpy.nan\n",
    "\n",
    "fairs = pd.read_excel(FILENAME, FAIR_SHEET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b42032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(value):\n",
    "    return isinstance(value, float) and math.isnan(value)\n",
    "\n",
    "def exec_query(query):\n",
    "    cursor = pyodbc.connect(CONNECTION_STRING).cursor()\n",
    "    cursor.execute(query)\n",
    "    rows = [tuple(r) for r in cursor.fetchall()]\n",
    "    headers = [column[0] for column in cursor.description]\n",
    "    data = [dict(zip(headers, row)) for row in rows]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaa8c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO_LINES_QUERY = '''\n",
    "        SELECT ITEMID, CAST(SALESQTY AS INT) AS SALESQTY, SHIPPINGDATECONFIRMED\n",
    "        FROM [MDC_AX2009SP1_PROD].[dbo].[SALESLINE]\n",
    "        WHERE DATAAREAID='mdc'\n",
    "        '''\n",
    "\n",
    "so_lines = pd.DataFrame(exec_query(SO_LINES_QUERY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d7be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = commits_orig.copy()\n",
    "commits = commits[commits['PartNumber'].notnull()] # filter out rows with empty part numbers\n",
    "commits['Type'] = 'Supply Commits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a51f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [col for col in commits.columns if isinstance(col, datetime)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9000f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_col in date_cols:\n",
    "    commits[date_col] = commits['PartNumber'].map(\n",
    "        so_lines.loc[\n",
    "            (so_lines['SHIPPINGDATECONFIRMED'] >= date_col)\n",
    "            & (so_lines['SHIPPINGDATECONFIRMED'] < date_col + timedelta(days=7))\n",
    "        ].groupby('ITEMID')['SALESQTY'].sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9993f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits.iloc[:, 5] = commits['PartNumber'].map(\n",
    "    so_lines.loc[\n",
    "        (so_lines['SHIPPINGDATECONFIRMED'] < date_cols[0])\n",
    "    ].groupby('ITEMID')['SALESQTY'].sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8757e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shipped = commits_orig.copy()\n",
    "shipped = shipped[shipped['PartNumber'].notnull()] # filter out rows with empty part numbers\n",
    "shipped['Type'] = 'Completed Shipments'\n",
    "shipped['Issues/Notes'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b8431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPS_LINES_QUERY = '''\n",
    "        SELECT ITEMID, CAST(QTY AS INT) AS QTY, DELIVERYDATE\n",
    "        FROM [MDC_AX2009SP1_PROD].[dbo].[CUSTPACKINGSLIPTRANS]\n",
    "        WHERE DATAAREAID='mdc'\n",
    "        '''\n",
    "\n",
    "sps_lines = pd.DataFrame(exec_query(SPS_LINES_QUERY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dcdb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_col in date_cols:\n",
    "    shipped[date_col] = shipped['PartNumber'].map(\n",
    "        sps_lines.loc[\n",
    "            (sps_lines['DELIVERYDATE'] >= date_col)\n",
    "            & (sps_lines['DELIVERYDATE'] < date_col + timedelta(days=7))\n",
    "        ].groupby('ITEMID')['QTY'].sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipped.iloc[:, 5] = shipped['PartNumber'].map(\n",
    "    sps_lines.loc[\n",
    "        (sps_lines['DELIVERYDATE'] < date_cols[0])\n",
    "    ].groupby('ITEMID')['QTY'].sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14469d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([commits, shipped]).sort_values(['PartNumber', 'Type'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad9414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_thru_col = combined.columns[5]\n",
    "totals_col = combined.columns[-2]\n",
    "\n",
    "combined[totals_col] = combined[[past_thru_col] + date_cols].sum(axis=1)\n",
    "\n",
    "combined[past_thru_col] = combined[past_thru_col].replace(0, numpy.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9268f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairs_filtered = fairs[fairs['Group#'] == 'Group 2'][['Lam Part No', 'FAIR Date']]\n",
    "\n",
    "combined_merged = pd.merge(combined, fairs_filtered, left_on='PartNumber', right_on='Lam Part No', how='left')\n",
    "\n",
    "combined_merged['FAIR Completed Date'] = combined_merged['FAIR Date']\n",
    "combined_merged = combined_merged.drop(columns=['Lam Part No', 'FAIR Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f10c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pkastner\\Documents\\lam-supply-commits\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "book = load_workbook(FILENAME)\n",
    "\n",
    "writer = pd.ExcelWriter(OUTPUT_FILENAME, engine='openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "combined_merged.to_excel(writer, sheet_name=UPDATED_SHEET_NAME, index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
